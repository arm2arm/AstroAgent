# ============================================================================
# Task Templates — CrewAI 1.9x YAML Configuration
# ============================================================================
# Each top-level key is a task identifier referenced in Python code.
# Supports {variable} placeholders resolved at runtime via str.format().
# ============================================================================

planning_task:
  description: >
    USER REQUEST: "{research_question}"

    {memory_context}

    Create a short plan (numbered steps) to implement this request.
    Include only what the user asked for.
  expected_output: >
    Numbered plan with clear steps

analysis_task:
  description: >
    Implement this plan:

    {analysis_plan}

    {memory_context}

    Specify which Python libraries and methods to use for each step.
    Be concise.
  expected_output: >
    Technical approach with library choices

coding_task:
  description: >
    USER REQUEST: "{research_question}"

    Write a complete Python script that does EXACTLY what is requested above.

    {context}
    {revision_hint}

    REQUIREMENTS:
    - Available libraries: {pre_install}
    - The script must run top-to-bottom without errors.
    - If you define functions, CALL them in `if __name__ == "__main__":`.
    - PRINT all key results to stdout.
    - Do NOT fetch remote data unless the user asked for it.
    - For plotting tasks: use matplotlib with Agg backend, save with
      plt.savefig("plot.png", dpi=150, bbox_inches="tight"), print
      "SAVED: plot.png", NEVER call plt.show().

    Return ONLY a ```python code block. No explanations outside it.

    REMINDER — the user asked: "{research_question}"
  expected_output: >
    Complete executable Python script in a ```python code block

review_task:
  description: >
    ORIGINAL USER REQUEST: "{research_question}"

    --- CODE ---
    {generated_code}

    --- EXECUTION OUTPUT ---
    {exec_summary}
    {artifact_info}
    {memory_context}

    REVIEW CHECKLIST:
    1. Does the code do what the user asked for?
       Re-read the request above. If the user asked to "plot sine
       in blue and cos in green" — does the code plot sine in blue
       and cosine in green? If not → NEEDS REVISION.
    2. Did it run without errors?
    3. If it should produce a plot, was an image file saved?
       (Check GENERATED FILES section.) No image → NEEDS REVISION.
    4. Are defined functions actually called?

    End with exactly one line: APPROVED or NEEDS REVISION.
    If NEEDS REVISION, list specific fixes as bullet points.
  expected_output: >
    Review report ending with APPROVED or NEEDS REVISION

summarization_task:
  description: >
    Summarize the following {label} into <= {target_tokens} tokens.
    Preserve constraints, data details, and actionable steps.
    Output concise bullet points.

    CONTENT:
    {content}
  expected_output: >
    Concise bullet summary
