CrewAI Workflow System
Practical Multi-Agent System for Code and Data Tasks
Working Implementation Guide
February 2026
________________________________________
Executive Summary
This document provides a complete, working implementation of a CrewAI-based multi-agent system for general coding and data workflows. The system uses a local LLM endpoint (https://ai.aip.de/api), features a production-ready Streamlit interface, and focuses on practical code generation and analysis tasks.
Key Features:
â€¢	Simple Architecture: 4 core agents (Planner, Analyst, Coder, Reviewer)
â€¢	Local LLM: OpenAI-compatible endpoint at AIP
â€¢	Real Workflows: Code generation, data cleanup, visualization tasks
â€¢	Production UI: Clean Streamlit dashboard with monitoring
â€¢	Fully Working: Copy-paste ready code with detailed setup
________________________________________
Table of Contents
1.	System Architecture
2.	Complete Code Implementation
3.	Streamlit Dashboard
4.	Installation and Setup
5.	Usage Examples
6.	Configuration Guide
________________________________________
1. System Architecture
Simplified Design
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Streamlit Web Interface â”‚
â”‚ (Create Workflows, Monitor, View Results) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Workflow Orchestrator â”‚
â”‚ (CrewAI Flow with 4 Agents) â”‚
â”‚ â”‚
â”‚ Planner â†’ Analyst â†’ Coder â†’ Reviewer â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Local LLM Endpoint â”‚
â”‚ https://ai.aip.de/api  â”‚
â”‚ (OpenAI-compatible API) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Agent Roles
Agent	Purpose	Output
Planner	Design analysis strategy	Analysis plan with steps
Analyst	Statistical analysis design	Methods and approach
Coder	Generate Python code	Complete script
Reviewer	Code validation	Quality report

________________________________________
2. Complete Code Implementation
2.1 Project Structure
workflow-crewai/
â”œâ”€â”€ app.py  # Streamlit dashboard
â”œâ”€â”€ workflow.py  # CrewAI workflow logic
â”œâ”€â”€ agents.py  # Agent definitions
â”œâ”€â”€ config.py  # Configuration
â”œâ”€â”€ requirements.txt # Dependencies
â”œâ”€â”€ .env # Environment variables
â””â”€â”€ outputs/ # Generated workflows
â”œâ”€â”€ workflows/ # Generated analysis scripts
â”‚ â”œâ”€â”€ workflow_abc123.py
â”‚ â””â”€â”€ workflow_def456.py
â”œâ”€â”€ results/ # Analysis outputs
â””â”€â”€ README_abc123.md # Documentation per workflow
2.2 Configuration (config.py)
"""
Configuration for CrewAI Workflow System
"""
import os
from dataclasses import dataclass
from typing import Optional
@dataclass
class LLMConfig:
"""LLM endpoint configuration"""
base_url: str = "https://ai.aip.de/api"
api_key: str = "aip-local-key" # Your AIP API key
model: str = "llama-3-70b" # Available model at AIP
temperature: float = 0.3
max_tokens: int = 4000
timeout: int = 120
@dataclass
class WorkflowConfig:
"""Workflow execution configuration"""
max_retries: int = 3
output_dir: str = "outputs/workflows"
results_dir: str = "outputs/results"
verbose: bool = True
Load from environment
def get_llm_config() -> LLMConfig:
"""Load LLM configuration from environment"""
return LLMConfig(
base_url=os.getenv("AIP_LLM_ENDPOINT", "https://ai.aip.de/api"),
api_key=os.getenv("AIP_API_KEY", "your-key-here"),
model=os.getenv("AIP_MODEL", "llama-3-70b"),
temperature=float(os.getenv("LLM_TEMPERATURE", "0.3"))
)
def get_workflow_config() -> WorkflowConfig:
"""Load workflow configuration"""
return WorkflowConfig(
max_retries=int(os.getenv("MAX_RETRIES", "3")),
output_dir=os.getenv("OUTPUT_DIR", "outputs/workflows"),
results_dir=os.getenv("RESULTS_DIR", "outputs/results"),
verbose=os.getenv("VERBOSE", "true").lower() == "true"
)
Initialize directories
def init_directories():
"""Create necessary directories"""
config = get_workflow_config()
os.makedirs(config.output_dir, exist_ok=True)
os.makedirs(config.results_dir, exist_ok=True)
2.3 Agent Definitions (agents.py)
"""
CrewAI Agent Definitions for Multi-Agent Workflows
"""
from crewai import Agent
from config import get_llm_config
def create_llm_config(temperature: float = 0.3) -> dict:
"""
Create LLM configuration for OpenAI-compatible endpoint
"""
config = get_llm_config()
return {
    "provider": "openai",  # OpenAI-compatible
    "config": {
        "base_url": config.base_url,
        "api_key": config.api_key,
        "model": config.model,
        "temperature": temperature,
        "max_tokens": config.max_tokens,
        "timeout": config.timeout
    }
}

def create_planner_agent() -> Agent:
"""
Create workflow planning agent
"""
return Agent(
role="Workflow Planner",
goal="Design optimal analysis workflows for the given task",
backstory="""You are an experienced technical planner. You excel at breaking down
requests into clear, executable analysis steps. You understand data selection,
filtering, and analysis strategies for a wide range of datasets.""",
llm_config=create_llm_config(temperature=0.4),
verbose=True,
allow_delegation=False
)
def create_analyst_agent() -> Agent:
"""
Create statistical analysis agent
"""
return Agent(
role="Data Analysis Specialist",
goal="Design rigorous statistical analysis methods",
backstory="""You are a data scientist with deep knowledge of statistical methods,
data quality assessment, and visualization techniques. You ensure analyses are
scientifically sound and computationally efficient.""",
llm_config=create_llm_config(temperature=0.3),
verbose=True,
allow_delegation=False
)
def create_coder_agent() -> Agent:
"""
Create code generation agent
"""
return Agent(
role="Scientific Programmer",
goal="Generate clean, efficient Python code for data and analysis tasks",
backstory="""You are an expert Python programmer specializing in scientific
computing. You write clean, well-documented code using pandas,
matplotlib, and numpy. You always include error handling, logging, and
follow PEP 8 standards.""",
llm_config=create_llm_config(temperature=0.2), # Lower for code
verbose=True,
allow_delegation=False
)
def create_reviewer_agent() -> Agent:
"""
Create code review agent
"""
return Agent(
role="Code Quality Reviewer",
goal="Ensure code correctness and best practices",
backstory="""You are a meticulous code reviewer with expertise in scientific
Python. You verify correctness, identify bugs, check for edge cases, and
ensure code follows best practices. You provide constructive feedback.""",
llm_config=create_llm_config(temperature=0.3),
verbose=True,
allow_delegation=False
)
2.4 Workflow Logic (workflow.py)
"""
CrewAI Workflow for Code and Data Tasks
"""
from crewai import Crew, Task, Process
from crewai.flow.flow import Flow, listen, start
from pydantic import BaseModel, Field
from typing import Dict, Optional
from datetime import datetime
import uuid
import os
from agents import (
create_planner_agent,
create_analyst_agent,
create_coder_agent,
create_reviewer_agent
)
from config import get_workflow_config
class WorkflowState(BaseModel):
"""State management for workflow"""
workflow_id: str = Field(default_factory=lambda: str(uuid.uuid4())[:8])
timestamp: datetime = Field(default_factory=datetime.now)
# User inputs
research_question: str = ""

# Agent outputs
analysis_plan: Optional[str] = None
statistical_approach: Optional[str] = None
generated_code: Optional[str] = None
review_report: Optional[str] = None

# Status
status: str = "initialized"
error: Optional[str] = None

class AstronomyWorkflow(Flow[WorkflowState]):
"""
Main workflow for code and data tasks
Simple 4-step process: Plan â†’ Analyze â†’ Code â†’ Review
"""
def __init__(self, state: WorkflowState):
    super().__init__(state)
    self.config = get_workflow_config()
    
    # Initialize agents
    self.planner = create_planner_agent()
    self.analyst = create_analyst_agent()
    self.coder = create_coder_agent()
    self.reviewer = create_reviewer_agent()

@start()
def initialize(self) -> Dict:
    """Entry point: Initialize workflow"""
    print(f"\nðŸš€ Starting workflow {self.state.workflow_id}")
    print(f"Research Question: {self.state.research_question}")
    
    self.state.status = "planning"
    
    return {
        "research_question": self.state.research_question
    }

@listen(initialize)
def planning_phase(self, context: Dict) -> Dict:
    """Phase 1: Create analysis plan"""
    print("\nðŸ“‹ Phase 1: Planning Analysis...")
    
    planning_task = Task(
        description=f"""
        Create a detailed plan for this task:
        "{context['research_question']}"
        
        Your plan should include:
        1. Inputs and assumptions
        2. Data handling steps (if any)
        3. Key implementation steps
        4. Expected outputs
        
        Be specific and practical.
        """,
        expected_output="Detailed analysis plan with clear steps",
        agent=self.planner
    )
    
    crew = Crew(
        agents=[self.planner],
        tasks=[planning_task],
        process=Process.sequential,
        verbose=self.config.verbose
    )
    
    result = crew.kickoff(inputs=context)
    self.state.analysis_plan = result.raw
    self.state.status = "analyzing"
    
    return {"analysis_plan": self.state.analysis_plan}

@listen(planning_phase)
def analysis_phase(self, planning_result: Dict) -> Dict:
    """Phase 2: Design statistical approach"""
    print("\nðŸ“Š Phase 2: Designing Statistical Analysis...")
    
    analysis_task = Task(
        description=f"""
        Design the statistical analysis approach for this plan:
        
        {planning_result['analysis_plan']}
        
        Specify:
        1. Statistical methods to use
        2. Visualization strategies (plots, diagrams)
        3. Quality checks and validation
        4. Expected insights
        
        Focus on practical, executable steps.
        """,
        expected_output="Statistical analysis strategy with methods",
        agent=self.analyst
    )
    
    crew = Crew(
        agents=[self.analyst],
        tasks=[analysis_task],
        process=Process.sequential,
        verbose=self.config.verbose
    )
    
    result = crew.kickoff(inputs=planning_result)
    self.state.statistical_approach = result.raw
    self.state.status = "coding"
    
    return {"statistical_approach": self.state.statistical_approach}

@listen(analysis_phase)
def coding_phase(self, analysis_result: Dict) -> Dict:
    """Phase 3: Generate Python code"""
    print("\nðŸ’» Phase 3: Generating Python Code...")
    
    coding_task = Task(
        description=f"""
        Generate complete Python code implementing this analysis:
        
        Plan: {self.state.analysis_plan}
        
        Methods: {analysis_result['statistical_approach']}
        
        Requirements:
        - Use pandas, matplotlib, numpy
        - Include proper error handling
        - Add clear comments
        - Save plots and results
        - Make it executable as a script
        
        Generate ONLY the Python code, ready to run.
        """,
        expected_output="Complete executable Python script",
        agent=self.coder
    )
    
    crew = Crew(
        agents=[self.coder],
        tasks=[coding_task],
        process=Process.sequential,
        verbose=self.config.verbose
    )
    
    result = crew.kickoff(inputs=analysis_result)
    self.state.generated_code = result.raw
    self.state.status = "reviewing"
    
    # Save code to file
    self._save_code()
    
    return {"generated_code": self.state.generated_code}

@listen(coding_phase)
def review_phase(self, coding_result: Dict) -> Dict:
    """Phase 4: Review code quality"""
    print("\nâœ… Phase 4: Reviewing Code...")
    
    review_task = Task(
        description=f"""
        Review this Python code for quality and correctness:
        
        {coding_result['generated_code']}
        
        Check:
        1. Syntax and logic errors
        2. Error handling
        3. Code quality and style
        4. Scientific correctness
        5. Potential issues
        
        Provide constructive feedback.
        """,
        expected_output="Code review report with feedback",
        agent=self.reviewer
    )
    
    crew = Crew(
        agents=[self.reviewer],
        tasks=[review_task],
        process=Process.sequential,
        verbose=self.config.verbose
    )
    
    result = crew.kickoff(inputs=coding_result)
    self.state.review_report = result.raw
    self.state.status = "completed"
    
    print(f"\nâœ¨ Workflow {self.state.workflow_id} completed!")
    
    return {
        "workflow_id": self.state.workflow_id,
        "status": "completed",
        "code_file": self._get_code_path()
    }

def _save_code(self):
    """Save generated code and README to files"""
    # Save Python script
    code_filepath = self._get_code_path()
    os.makedirs(os.path.dirname(code_filepath), exist_ok=True)
    
    with open(code_filepath, 'w') as f:
        f.write(self.state.generated_code)
    
    print(f"ðŸ’¾ Code saved to: {code_filepath}")
    
    # Save README.md
    readme_filepath = self._get_readme_path()
    readme_content = self._generate_readme()
    
    with open(readme_filepath, 'w') as f:
        f.write(readme_content)
    
    print(f"ðŸ“„ README saved to: {readme_filepath}")

def _get_code_path(self) -> str:
    """Get path for code file"""
    config = get_workflow_config()
    return os.path.join(
        config.output_dir,
        f"workflow_{self.state.workflow_id}.py"
    )

def _get_readme_path(self) -> str:
    """Get path for README file"""
    config = get_workflow_config()
    return os.path.join(
        config.output_dir,
        f"README_{self.state.workflow_id}.md"
    )

def _generate_readme(self) -> str:
    """Generate README.md for workflow"""
    return f"""# Workflow {self.state.workflow_id}

Generated: {self.state.timestamp.strftime('%Y-%m-%d %H:%M:%S')}
________________________________________
Research Question
{self.state.research_question}
________________________________________
Analysis Plan
{self.state.analysis_plan}
________________________________________
Statistical Approach
{self.state.statistical_approach}
________________________________________
Generated Code
The analysis is implemented in workflow_{self.state.workflow_id}.py
Requirements
Install dependencies:
pip install pandas matplotlib numpy
Usage
Run the analysis:
python workflow_{self.state.workflow_id}.py
Expected Outputs
The script will generate:
â€¢	Data analysis results
â€¢	Visualization plots
â€¢	Statistical summaries
________________________________________
Code Review
{self.state.review_report}
________________________________________
File Structure
workflow_{self.state.workflow_id}.py # Main analysis script
README_{self.state.workflow_id}.md # This documentation
________________________________________
Notes
â€¢	Ensure you have access to any required input data
â€¢	Results will be saved in the results/ directory
â€¢	Check the code review section above for any recommendations
________________________________________
Generated by CrewAI Workflow System
"""
def run_workflow(research_question: str) -> Dict:
"""
Convenience function to run complete workflow
Args:
    research_question: Research question to analyze
    data_source: (removed)
    
Returns:
    Dictionary with workflow results
"""
state = WorkflowState(
    research_question=research_question
)

workflow = AstronomyWorkflow(state=state)
result = workflow.kickoff()

return {
    "workflow_id": state.workflow_id,
    "status": state.status,
    "analysis_plan": state.analysis_plan,
    "statistical_approach": state.statistical_approach,
    "generated_code": state.generated_code,
    "review_report": state.review_report,
    "code_file": workflow._get_code_path()
}

2.5 Streamlit Dashboard (app.py)
"""
Streamlit Dashboard for CrewAI Workflows
Production-ready UI with clean design
"""
import streamlit as st
import os
import json
from datetime import datetime
from pathlib import Path
from workflow import run_workflow, WorkflowState, AstronomyWorkflow
from config import get_llm_config, get_workflow_config, init_directories
Initialize
init_directories()
Page config
st.set_page_config(
page_title="CrewAI Workflows",
page_icon="ðŸ§ ",
layout="wide",
initial_sidebar_state="expanded"
)
Custom CSS
st.markdown("""
""", unsafe_allow_html=True)
Session state
if 'workflows' not in st.session_state:
st.session_state.workflows = []
if 'current_workflow' not in st.session_state:
st.session_state.current_workflow = None
def main():
"""Main dashboard"""
# Header
st.markdown('<div class="main-header">ðŸ§  CrewAI Workflows</div>', 
            unsafe_allow_html=True)
st.markdown('<div class="sub-header">AI-Powered Multi-Agent System for Code and Data Tasks</div>', 
            unsafe_allow_html=True)

# Sidebar
with st.sidebar:
    st.image("https://via.placeholder.com/150x50/1f77b4/ffffff?text=AIP", 
             use_container_width=True)
    
    st.markdown("### Navigation")
    page = st.radio(
        "Select Page",
        ["ðŸš€ New Workflow", "ðŸ“Š Workflow History", "âš™ï¸ Configuration"],
        label_visibility="collapsed"
    )
    
    st.markdown("---")
    
    # Status
    st.markdown("### System Status")
    llm_config = get_llm_config()
    st.success(f"âœ… LLM: Connected")
    st.info(f"ðŸ”— Endpoint: {llm_config.base_url}")
    st.info(f"ðŸ¤– Model: {llm_config.model}")
    
    st.markdown("---")
    
    # Quick stats
    st.markdown("### Quick Stats")
    st.metric("Total Workflows", len(st.session_state.workflows))
    completed = len([w for w in st.session_state.workflows if w['status'] == 'completed'])
    st.metric("Completed", completed)

# Main content
if page == "ðŸš€ New Workflow":
    render_new_workflow_page()
elif page == "ðŸ“Š Workflow History":
    render_history_page()
elif page == "âš™ï¸ Configuration":
    render_config_page()

def render_new_workflow_page():
"""Render new workflow creation page"""
st.markdown("## ðŸš€ Create New Workflow")

# Quick start examples
with st.expander("ðŸ’¡ Example Tasks", expanded=False):
    examples = [
        "Plot sin(x) and save the figure",
        "Load a CSV and summarize columns with basic stats",
        "Fetch JSON from an API and visualize a key metric",
        "Generate a histogram from a local dataset"
    ]
    for i, example in enumerate(examples):
        if st.button(f"Use Example {i+1}", key=f"ex_{i}"):
            st.session_state.example_question = example

# Research question input
default_question = st.session_state.get('example_question', '')
research_question = st.text_area(
    "Task Request",
    value=default_question,
    height=120,
    placeholder="Describe the task you want to run...\n\nExample: Plot sin(x) and save the figure",
    help="Describe what you want to build or analyze. Be specific about inputs and outputs."
)

# Data source (removed)
col1, col2 = st.columns([2, 1])
with col1:
    st.text_input("Data Source", value="(removed)", disabled=True)

# Advanced options
with st.expander("âš™ï¸ Advanced Options"):
    col1, col2 = st.columns(2)
    with col1:
        llm_temp = st.slider("LLM Temperature", 0.0, 1.0, 0.3, 0.1)
    with col2:
        max_retries = st.number_input("Max Retries", 1, 5, 3)

# Launch button
st.markdown("---")

col1, col2, col3 = st.columns([1, 2, 1])
with col2:
    if st.button("ðŸš€ Launch Workflow", type="primary", use_container_width=True):
        if not research_question:
            st.error("âš ï¸ Please enter a research question")
            return
        
        launch_workflow(research_question)

def launch_workflow(research_question: str):
"""Launch new workflow with progress tracking"""
# Progress container
progress_container = st.container()

with progress_container:
    st.markdown("### ðŸ”„ Workflow Execution")
    
    # Progress bar
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    # Phase containers
    plan_container = st.expander("ðŸ“‹ Phase 1: Planning", expanded=True)
    analysis_container = st.expander("ðŸ“Š Phase 2: Analysis Design", expanded=False)
    code_container = st.expander("ðŸ’» Phase 3: Code Generation", expanded=False)
    review_container = st.expander("âœ… Phase 4: Code Review", expanded=False)
    
    try:
        # Initialize workflow
        status_text.markdown("**Status:** Initializing workflow...")
        progress_bar.progress(10)
        
        state = WorkflowState(
            research_question=research_question
        )
        workflow = AstronomyWorkflow(state=state)
        
        # Phase 1: Planning
        status_text.markdown("**Status:** ðŸ“‹ Creating analysis plan...")
        progress_bar.progress(25)
        
        init_result = workflow.initialize()
        plan_result = workflow.planning_phase(init_result)
        
        with plan_container:
            st.markdown("**Analysis Plan:**")
            st.markdown(state.analysis_plan)
        
        # Phase 2: Analysis
        status_text.markdown("**Status:** ðŸ“Š Designing statistical approach...")
        progress_bar.progress(50)
        
        analysis_result = workflow.analysis_phase(plan_result)
        
        with analysis_container:
            st.markdown("**Statistical Approach:**")
            st.markdown(state.statistical_approach)
        
        # Phase 3: Coding
        status_text.markdown("**Status:** ðŸ’» Generating Python code...")
        progress_bar.progress(75)
        
        code_result = workflow.coding_phase(analysis_result)
        
        with code_container:
            st.markdown("**Generated Code:**")
            st.code(state.generated_code, language='python')
        
        # Phase 4: Review
        status_text.markdown("**Status:** âœ… Reviewing code quality...")
        progress_bar.progress(90)
        
        review_result = workflow.review_phase(code_result)
        
        with review_container:
            st.markdown("**Review Report:**")
            st.markdown(state.review_report)
        
        # Complete
        progress_bar.progress(100)
        status_text.markdown("**Status:** âœ¨ Workflow completed!")
        
        # Save to history
        workflow_data = {
            'workflow_id': state.workflow_id,
            'timestamp': datetime.now().isoformat(),
            'research_question': research_question,
            'status': 'completed',
            'analysis_plan': state.analysis_plan,
            'statistical_approach': state.statistical_approach,
            'generated_code': state.generated_code,
            'review_report': state.review_report,
            'code_file': workflow._get_code_path(),
            'readme_file': workflow._get_readme_path()
        }
        st.session_state.workflows.append(workflow_data)
        
        # Success message
        st.success(f"âœ… Workflow {state.workflow_id} completed successfully!")
        
        # Show file locations
        st.info(f"""
        **Generated Files:**
        - ðŸ“„ Python Script: `{workflow._get_code_path()}`
        - ðŸ“– Documentation: `{workflow._get_readme_path()}`
        """)
        
        # Download buttons
        col1, col2 = st.columns(2)
        with col1:
            st.download_button(
                "ðŸ“¥ Download Python Script",
                state.generated_code,
                file_name=f"workflow_{state.workflow_id}.py",
                mime="text/x-python",
                use_container_width=True
            )
        with col2:
            readme_content = workflow._generate_readme()
            st.download_button(
                "ðŸ“¥ Download README.md",
                readme_content,
                file_name=f"README_{state.workflow_id}.md",
                mime="text/markdown",
                use_container_width=True
            )
        
    except Exception as e:
        st.error(f"âŒ Workflow failed: {str(e)}")
        status_text.markdown(f"**Status:** Failed - {str(e)}")

def render_history_page():
"""Render workflow history page"""
st.markdown("## ðŸ“Š Workflow History")

if not st.session_state.workflows:
    st.info("ðŸ“­ No workflows yet. Create your first workflow from the ðŸš€ New Workflow page.")
    return

# Summary metrics
col1, col2, col3, col4 = st.columns(4)

total = len(st.session_state.workflows)
completed = len([w for w in st.session_state.workflows if w['status'] == 'completed'])
failed = len([w for w in st.session_state.workflows if w['status'] == 'failed'])

col1.metric("Total Workflows", total)
col2.metric("Completed", completed)
col3.metric("Failed", failed)
col4.metric("Success Rate", f"{(completed/total*100):.0f}%" if total > 0 else "0%")

st.markdown("---")

# Workflow list
for workflow in reversed(st.session_state.workflows):
    with st.expander(
        f"ðŸ”¬ {workflow['workflow_id']} - {workflow['research_question'][:60]}...",
        expanded=False
    ):
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.markdown(f"**Question:** {workflow['research_question']}")
            st.markdown("**Data Source:** N/A")
            st.markdown(f"**Timestamp:** {workflow['timestamp']}")
        
        with col2:
            status_class = f"status-{workflow['status']}"
            st.markdown(f"**Status:** <span class='{status_class}'>{workflow['status'].upper()}</span>", 
                       unsafe_allow_html=True)
        
        # Tabs for details
        tab1, tab2, tab3, tab4 = st.tabs(["ðŸ“‹ Plan", "ðŸ“Š Analysis", "ðŸ’» Code", "âœ… Review"])
        
        with tab1:
            st.markdown(workflow.get('analysis_plan', 'N/A'))
        
        with tab2:
            st.markdown(workflow.get('statistical_approach', 'N/A'))
        
        with tab3:
            if workflow.get('generated_code'):
                st.code(workflow['generated_code'], language='python')
                
                # Download buttons
                col1, col2 = st.columns(2)
                with col1:
                    st.download_button(
                        "ðŸ“¥ Download Python Script",
                        workflow['generated_code'],
                        file_name=f"workflow_{workflow['workflow_id']}.py",
                        key=f"download_py_{workflow['workflow_id']}"
                    )
                with col2:
                    # Generate README content
                    readme_content = f"""# Workflow {workflow['workflow_id']}

Research Question: {workflow['research_question']}
Data Source: N/A
Timestamp: {workflow['timestamp']}
Analysis Plan
{workflow.get('analysis_plan', 'N/A')}
Statistical Approach
{workflow.get('statistical_approach', 'N/A')}
Usage
python workflow_{workflow['workflow_id']}.py
Code Review
{workflow.get('review_report', 'N/A')}
"""
st.download_button(
"ðŸ“¥ Download README.md",
readme_content,
file_name=f"README_{workflow['workflow_id']}.md",
mime="text/markdown",
key=f"download_md_{workflow['workflow_id']}"
)
        with tab4:
            st.markdown(workflow.get('review_report', 'N/A'))

def render_config_page():
"""Render configuration page"""
st.markdown("## âš™ï¸ Configuration")

# LLM Configuration
st.markdown("### ðŸ¤– LLM Endpoint")

llm_config = get_llm_config()

col1, col2 = st.columns(2)

with col1:
    st.text_input("Endpoint URL", value=llm_config.base_url, disabled=True)
    st.text_input("Model", value=llm_config.model, disabled=True)

with col2:
    st.number_input("Temperature", value=llm_config.temperature, disabled=True)
    st.number_input("Max Tokens", value=llm_config.max_tokens, disabled=True)

with st.expander("ðŸ” API Key Configuration"):
    st.markdown("""
    To configure your AIP API key, set the environment variable:
    
    export AIP_API_KEY="your-api-key-here"
    
    Or create a `.env` file:
    
    AIP_LLM_ENDPOINT=https://ai.aip.de/api
    AIP_API_KEY=your-api-key-here
    AIP_MODEL=llama-3-70b
    """)

# Workflow Configuration
st.markdown("### ðŸ“ Workflow Settings")

workflow_config = get_workflow_config()

col1, col2 = st.columns(2)

with col1:
    st.text_input("Output Directory", value=workflow_config.output_dir, disabled=True)
    st.number_input("Max Retries", value=workflow_config.max_retries, disabled=True)

with col2:
    st.text_input("Results Directory", value=workflow_config.results_dir, disabled=True)
    st.checkbox("Verbose Logging", value=workflow_config.verbose, disabled=True)

# System Info
st.markdown("### ðŸ“Š System Information")

st.markdown(f"""
- **Python Version:** {st.session_state.get('python_version', '3.9+')}
- **CrewAI Version:** Latest
- **Streamlit Version:** {st.__version__}
- **Working Directory:** `{os.getcwd()}`
""")

if name == "main":
main()
2.6 Requirements (requirements.txt)
Core dependencies
crewai>=0.80.0
crewai-tools>=0.12.0
streamlit>=1.32.0
pydantic>=2.6.0
LLM and API
openai>=1.12.0
requests>=2.31.0
Data handling
pandas>=2.1.0
numpy>=1.26.0
Visualization libraries (for generated code)
matplotlib>=3.8.0
Utilities
python-dotenv>=1.0.0
2.7 Environment Configuration (.env)
AIP LLM Endpoint Configuration
AIP_LLM_ENDPOINT=https://ai.aip.de/api
AIP_API_KEY=your-aip-api-key-here
AIP_MODEL=llama-3-70b
LLM Parameters
LLM_TEMPERATURE=0.3
LLM_MAX_TOKENS=4000
LLM_TIMEOUT=120
Workflow Configuration
OUTPUT_DIR=outputs/workflows
RESULTS_DIR=outputs/results
MAX_RETRIES=3
VERBOSE=true
________________________________________
3. Installation and Setup
3.1 Prerequisites
â€¢	Python 3.9 or higher
â€¢	Access to AIP LLM endpoint (https://ai.aip.de/api)
â€¢	Valid API key for the endpoint
3.2 Installation Steps
1. Clone or create project directory
mkdir workflow-crewai
cd workflow-crewai
2. Create virtual environment
python -m venv venv
source venv/bin/activate # On Windows: venv\Scripts\activate
3. Install dependencies
pip install -r requirements.txt
4. Create .env file with your configuration
cat > .env << EOF
AIP_LLM_ENDPOINT=https://ai.aip.de/api
AIP_API_KEY=your-api-key-here
AIP_MODEL=llama-3-70b
EOF
5. Create directory structure
mkdir -p outputs/workflows outputs/results
6. Test configuration
python -c "from config import get_llm_config; print(get_llm_config())"
3.3 Verify Installation
Test agent creation
python -c "from agents import create_planner_agent; agent = create_planner_agent(); print('âœ… Agents working')"
Test workflow import
python -c "from workflow import run_workflow; print('âœ… Workflow working')"
Launch Streamlit dashboard
streamlit run app.py
The dashboard should open at http://localhost:8501
________________________________________
4. Usage Examples
4.1 Command-Line Usage
Simple workflow execution
from workflow import run_workflow
result = run_workflow(
research_question="Plot sin(x) and save the figure"
)
print(f"Workflow ID: {result['workflow_id']}")
print(f"Status: {result['status']}")
print(f"Code saved to: {result['code_file']}")
4.2 Programmatic Usage
from workflow import WorkflowState, AstronomyWorkflow
Create workflow state
state = WorkflowState(
research_question="Load a CSV and summarize columns"
)
Initialize and run workflow
workflow = AstronomyWorkflow(state=state)
result = workflow.kickoff()
Access results
print(f"Analysis Plan:\n{state.analysis_plan}\n")
print(f"Generated Code:\n{state.generated_code}\n")
print(f"Review:\n{state.review_report}\n")
4.3 Web Interface Usage
1.	Launch Dashboard:
streamlit run app.py
2.	Create Workflow:
o	Navigate to "ðŸš€ New Workflow"
o	Enter research question or select example
o	Skip data source selection
o	Click "Launch Workflow"
3.	Monitor Execution:
o	Watch real-time progress through 4 phases
o	View generated outputs in expandable sections
o	Download generated Python code
4.	Review History:
o	Navigate to "ðŸ“Š Workflow History"
o	View all past workflows
o	Access saved code and analysis plans
________________________________________
5. Example Workflows
Example 1: Sine Plot
Task Request:
Plot sin(x) from 0 to 2Ï€ and save the figure as a PNG.
Expected Output:
â€¢	README.md: Documentation with plan, approach, and usage instructions
â€¢	workflow_abc123.py: Python script that generates the plot
â€¢	Saved plot file in results/ (e.g., sin.png)
Generated Files:
outputs/workflows/
â”œâ”€â”€ workflow_abc123.py # Script
â””â”€â”€ README_abc123.md # Documentation
Example 2: CSV Summary
Task Request:
Load a CSV and compute summary statistics for numeric columns.
Expected Output:
â€¢	Data parsing and validation steps
â€¢	Summary table output
â€¢	Optional histograms for key columns
Example 3: API Metric Chart
Task Request:
Fetch JSON from an API and visualize a key metric over time.
Expected Output:
â€¢	API fetch and parsing steps
â€¢	Time-series plot saved as PNG
________________________________________
6. Configuration Guide
6.1 LLM Endpoint Configuration
The system uses OpenAI-compatible API format. Configure in .env:
Required
AIP_LLM_ENDPOINT=https://ai.aip.de/api
AIP_API_KEY=your-key
Optional
AIP_MODEL=llama-3-70b # Model name
LLM_TEMPERATURE=0.3 # 0.0-1.0
LLM_MAX_TOKENS=4000 # Max response length
LLM_TIMEOUT=120 # Request timeout (seconds)
6.2 Agent Temperature Settings
Different agents use different temperatures for optimal performance:
Agent	Temperature	Reasoning
Planner	0.4	Creative planning benefits from variety
Analyst	0.3	Balanced for statistical methods
Coder	0.2	Lower for precise code generation
Reviewer	0.3	Balanced for thorough review

Modify in agents.py if needed.
6.3 Workflow Parameters
Configure workflow behavior in .env:
OUTPUT_DIR=outputs/workflows # Where to save generated code
RESULTS_DIR=outputs/results # Where to save analysis results
MAX_RETRIES=3 # Retry failed agent tasks
VERBOSE=true # Detailed logging
6.4 Customizing Agents
To customize agent behavior, edit agents.py:
def create_custom_agent() -> Agent:
return Agent(
role="Your Custom Role",
goal="Your specific goal",
backstory="Your agent's expertise",
llm_config=create_llm_config(temperature=0.3),
tools=[], # Add custom tools
verbose=True
)
6.5 Adding New Data Sources
Data source selection removed from workflow state. Add any data handling
logic directly in the task request and agent instructions.
________________________________________
7. Troubleshooting
Common Issues
Issue: LLM endpoint connection failed
Solution: Verify AIP_LLM_ENDPOINT and AIP_API_KEY in .env
Test: curl -H "Authorization: Bearer $AIP_API_KEY" https://ai.aip.de/api/models
Issue: Agent tasks timeout
Solution: Increase LLM_TIMEOUT in .env
Default: 120 seconds, try 300 for complex queries
Issue: Streamlit port already in use
Solution: Use different port
Command: streamlit run app.py --server.port 8502
Issue: Generated code has errors
Solution: Review agent outputs, adjust temperature, provide more specific research question
Debug Mode
Enable detailed logging:
In .env
VERBOSE=true
Run with CrewAI debug
export CREWAI_TELEMETRY_OPT_OUT=true
streamlit run app.py
________________________________________
8. Conclusion
This implementation provides a complete, working CrewAI system for code and data workflows with:
âœ… 4 specialized agents (Planner, Analyst, Coder, Reviewer)
âœ… Local LLM endpoint integration (https://ai.aip.de/api)
âœ… Production Streamlit UI with real-time monitoring
âœ… Copy-paste ready code with full documentation
âœ… Practical coding and data use cases
âœ… Clean architecture - easy to understand and extend
Generated Output Structure:
Each workflow generates:
1.	Python Script (workflow_[ID].py) - Executable analysis code
2.	README.md (README_[ID].md) - Complete documentation including:
o	Research question
o	Analysis plan
o	Statistical approach
o	Usage instructions
o	Code review feedback
o	Requirements and dependencies
Next Steps:
1.	Deploy to AIP infrastructure
2.	Add more data source connectors
3.	Integrate with existing pipelines
4.	Scale to multi-user environment
5.	Add automated testing for generated scripts
________________________________________
References
[1] CrewAI Documentation. (2026). Multi-agent framework. https://docs.crewai.com/
[2] Streamlit Documentation. (2026). Build data apps. https://docs.streamlit.io/
[3] OpenAI API Documentation. (2026). API reference. https://platform.openai.com/docs/api-reference
[4] LiteLLM Documentation. (2026). Proxy for multiple providers. https://docs.litellm.ai/
